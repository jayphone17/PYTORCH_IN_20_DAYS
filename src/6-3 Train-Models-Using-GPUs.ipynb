{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81301158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度学习的训练过程常常非常耗时，一个模型训练几个小时是家常便饭，\n",
    "\n",
    "# 训练几天也是常有的事情，有时候甚至要训练几十天。\n",
    "\n",
    "# 训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。\n",
    "\n",
    "# 当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。\n",
    "\n",
    "# 当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU来进行加速。\n",
    "\n",
    "# Pytorch中使用GPU加速模型非常简单，只要将模型和数据移动到GPU上。核心代码只有以下几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19bddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "# ... \n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device) # 移动模型到cuda\n",
    "\n",
    "# 训练模型\n",
    "# ...\n",
    "\n",
    "# features = features.to(device) # 移动数据到cuda\n",
    "# labels = labels.to(device) \n",
    "# 或者  labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151faf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果要使用多个GPU训练模型，也非常简单。只需要在将模型设置为数据并行风格模型。\n",
    "\n",
    "# 则模型移动到GPU上之后，会在每一个GPU上拷贝一个副本，\n",
    "\n",
    "# 并把数据平分到各个GPU上进行训练。核心代码如下。\n",
    "\n",
    "# #定义模型\n",
    "# ... \n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model) # 包装为并行风格模型\n",
    "\n",
    "# # 训练模型\n",
    "# ...\n",
    "# features = features.to(device) # 移动数据到cuda\n",
    "# labels = labels.to(device) # 或者 labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94cf9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d5a965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_cuda= True\n",
      "gpu_count= 1\n"
     ]
    }
   ],
   "source": [
    "# 1，查看gpu信息\n",
    "if_cuda = torch.cuda.is_available()\n",
    "print(\"if_cuda=\",if_cuda)\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(\"gpu_count=\",gpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b53cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "True\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 2，将张量在gpu和cpu间移动\n",
    "tensor = torch.rand((100,100))\n",
    "tensor_gpu = tensor.to(\"cuda:0\") # 或者 tensor_gpu = tensor.cuda()\n",
    "print(tensor_gpu.device)\n",
    "print(tensor_gpu.is_cuda)\n",
    "\n",
    "tensor_cpu = tensor_gpu.to(\"cpu\") # 或者 tensor_cpu = tensor_gpu.cpu() \n",
    "print(tensor_cpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "797a6c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 3，将模型中的全部张量移动到gpu上\n",
    "net = nn.Linear(2,1)\n",
    "print(next(net.parameters()).is_cuda)\n",
    "net.to(\"cuda:0\") # 将模型中的全部参数张量依次到GPU上，注意，无需重新赋值为 net = net.to(\"cuda:0\")\n",
    "print(next(net.parameters()).is_cuda)\n",
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d02c88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[0]\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4，创建支持多个gpu数据并行的模型\n",
    "linear = nn.Linear(2,1)\n",
    "print(next(linear.parameters()).device)\n",
    "\n",
    "model = nn.DataParallel(linear)\n",
    "print(model.device_ids)\n",
    "print(next(model.module.parameters()).device) \n",
    "\n",
    "#注意保存参数时要指定保存model.module的参数\n",
    "torch.save(model.module.state_dict(), \"../data/model_parameter.pkl\") \n",
    "\n",
    "linear = nn.Linear(2,1)\n",
    "linear.load_state_dict(torch.load(\"../data/model_parameter.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b3c777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5，清空cuda缓存\n",
    "\n",
    "# 该方法在cuda超内存时十分有用\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e0803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一，矩阵乘法范例\n",
    "# 下面分别使用CPU和GPU作一个矩阵乘法，并比较其计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a08fa1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af50e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3670179843902588\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 使用cpu\n",
    "a = torch.rand((10000,200))\n",
    "b = torch.rand((200,10000))\n",
    "tic = time.time()\n",
    "c = torch.matmul(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(toc-tic)\n",
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3073a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012964725494384766\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 使用gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "a = torch.rand((10000,200),device = device) #可以指定在GPU上创建张量\n",
    "b = torch.rand((200,10000)) #也可以在CPU上创建张量后移动到GPU上\n",
    "b = b.to(device) #或者 b = b.cuda() if torch.cuda.is_available() else b \n",
    "tic = time.time()\n",
    "c = torch.matmul(a,b)\n",
    "toc = time.time()\n",
    "print(toc-tic)\n",
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a38ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二，线性回归范例\n",
    "# 下面对比使用CPU和GPU训练一个线性回归模型的效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f48cd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1，使用CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d893427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "n = 1000000 #样本数量\n",
    "\n",
    "X = 10*torch.rand([n,2])-5.0  #torch.rand是均匀分布 \n",
    "w0 = torch.tensor([[2.0,-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @表示矩阵乘法,增加正态扰动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58769d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class LinearRegression(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn_like(w0))\n",
    "        self.b = nn.Parameter(torch.zeros_like(b0))\n",
    "    #正向传播\n",
    "    def forward(self,x): \n",
    "        return x@self.w.t() + self.b\n",
    "        \n",
    "linear = LinearRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34d72301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'loss': 177.27825927734375}\n",
      "{'epoch': 50, 'loss': 33.048404693603516}\n",
      "{'epoch': 100, 'loss': 9.05585765838623}\n",
      "{'epoch': 150, 'loss': 4.494906902313232}\n",
      "{'epoch': 200, 'loss': 4.025531768798828}\n",
      "{'epoch': 250, 'loss': 4.00158166885376}\n",
      "{'epoch': 300, 'loss': 4.0010528564453125}\n",
      "{'epoch': 350, 'loss': 4.001049518585205}\n",
      "{'epoch': 400, 'loss': 4.001049518585205}\n",
      "{'epoch': 450, 'loss': 4.001049518585205}\n",
      "time used: 8.321749448776245\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "def train(epoches):\n",
    "    tic = time.time()\n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = linear(X) \n",
    "        loss = loss_func(Y_pred,Y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if epoch%50==0:\n",
    "            print({\"epoch\":epoch,\"loss\":loss.item()})\n",
    "    toc = time.time()\n",
    "    print(\"time used:\",toc-tic)\n",
    "\n",
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeb5ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2，使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dad76c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() =  True\n",
      "X.device: cuda:0\n",
      "Y.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "n = 1000000 #样本数量\n",
    "\n",
    "X = 10*torch.rand([n,2])-5.0  #torch.rand是均匀分布 \n",
    "w0 = torch.tensor([[2.0,-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @表示矩阵乘法,增加正态扰动\n",
    "\n",
    "# 移动到GPU上\n",
    "print(\"torch.cuda.is_available() = \",torch.cuda.is_available())\n",
    "X = X.cuda()\n",
    "Y = Y.cuda()\n",
    "print(\"X.device:\",X.device)\n",
    "print(\"Y.device:\",Y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a68c969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if on cuda: True\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "class LinearRegression(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn_like(w0))\n",
    "        self.b = nn.Parameter(torch.zeros_like(b0))\n",
    "    #正向传播\n",
    "    def forward(self,x): \n",
    "        return x@self.w.t() + self.b\n",
    "        \n",
    "linear = LinearRegression() \n",
    "\n",
    "# 移动模型到GPU上\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "linear.to(device)\n",
    "\n",
    "#查看模型是否已经移动到GPU上\n",
    "print(\"if on cuda:\",next(linear.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97c78b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'loss': 211.25192260742188}\n",
      "{'epoch': 50, 'loss': 33.402137756347656}\n",
      "{'epoch': 100, 'loss': 9.01778793334961}\n",
      "{'epoch': 150, 'loss': 4.488458633422852}\n",
      "{'epoch': 200, 'loss': 4.025352954864502}\n",
      "{'epoch': 250, 'loss': 4.001964569091797}\n",
      "{'epoch': 300, 'loss': 4.001456260681152}\n",
      "{'epoch': 350, 'loss': 4.001453399658203}\n",
      "{'epoch': 400, 'loss': 4.001453399658203}\n",
      "{'epoch': 450, 'loss': 4.001453876495361}\n",
      "time used: 1.1210017204284668\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "def train(epoches):\n",
    "    tic = time.time()\n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = linear(X) \n",
    "        loss = loss_func(Y_pred,Y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if epoch%50==0:\n",
    "            print({\"epoch\":epoch,\"loss\":loss.item()})\n",
    "    toc = time.time()\n",
    "    print(\"time used:\",toc-tic)\n",
    "    \n",
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48be149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由此看来GPU真的比CPU效率高很多！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
